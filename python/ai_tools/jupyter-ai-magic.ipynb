{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f4d6c-6443-47f9-bcdd-dad895e5cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install langchain\n",
    "#!pip install langchain-openai\n",
    "#!pip install jupyter-ai # for the side chat functionality\n",
    "#!pip install jupyter-ai-magics # for magic commands\n",
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6380ae4-a59b-4ef7-aba4-154a1e86a361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779c3891-8e16-4bf6-a922-12aa7e0f86e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "open_ai_key = os.getenv('OPENAI_API_DOCSTRING_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c15ae9c-336e-4906-a835-1b8de355addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e0e696-7a5f-4887-b4c0-7052821220a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:amazon.titan-text-lite-v1`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:cohere.command-r-v1:0`</li><li>`bedrock:cohere.command-r-plus-v1:0`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li><li>`bedrock:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock:mistral.mistral-large-2402-v1:0`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-opus-20240229-v1:0`</li></ul> |\n",
       "| `azure-chat-openai` | `AZURE_OPENAI_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0125`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li><li>`openai-chat:gpt-4o`</li></ul> |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:amazon.titan-text-lite-v1\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:cohere.command-r-v1:0\n",
       "* bedrock:cohere.command-r-plus-v1:0\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "* bedrock:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock:mistral.mistral-large-2402-v1:0\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-opus-20240229-v1:0\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable: AZURE_OPENAI_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0125\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "* openai-chat:gpt-4o\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d81ea126-776f-4491-8e2d-eabb76b42e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0125`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li><li>`openai-chat:gpt-4o`</li></ul> |\n"
      ],
      "text/plain": [
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0125\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "* openai-chat:gpt-4o\n",
       "\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list openai-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4452182-f3f7-4f2a-ac20-792c86fd6a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def fibonacci(n):\n",
       "    fib_series = []\n",
       "    a, b = 0, 1\n",
       "    for _ in range(n):\n",
       "        fib_series.append(a)\n",
       "        a, b = b, a + b\n",
       "    return fib_series\n",
       "\n",
       "n = 10\n",
       "print(fibonacci(n))\n",
       "```\n",
       "\n",
       "Output:\n",
       "```\n",
       "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-3.5-turbo\n",
    "write a function to compute the first n numbers of the Fibonacci series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb5d9a4-fafe-46ad-8b29-c4ef1282cf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "function to compute the first n numbers of the Fibonacci series\n",
    "provide the docstring for the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d156a19c-596c-45d9-a289-266b1fd9ca1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(n):\n",
    "    \"\"\"\n",
    "    Calculate the first n numbers of the Fibonacci series.\n",
    "\n",
    "    Parameters:\n",
    "    n (int): The number of Fibonacci numbers to calculate.\n",
    "\n",
    "    Returns:\n",
    "    list: A list containing the first n Fibonacci numbers.\n",
    "    \"\"\"\n",
    "    fib = [0, 1]\n",
    "    for i in range(2, n):\n",
    "        fib.append(fib[i-1] + fib[i-2])\n",
    "    return fib\n",
    "\n",
    "# Test the function\n",
    "n = 10\n",
    "print(fibonacci(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c247653a-12d6-4955-8e63-075cd1a24421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Write the function in the above cell in a recusrive form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8654f419-fbca-422a-9315-25f51b846e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci_recursive(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    else:\n",
    "        return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10140824-506a-4371-9740-bdacada55f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "write a function to compute the factorial of a number recursively\n",
    "provide a docstring, run it for n=10 and print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab904f8b-4f33-4170-970c-74c15365a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    \"\"\"\n",
    "    Compute the factorial of a number recursively.\n",
    "    \n",
    "    Parameters:\n",
    "    n (int): The number to compute the factorial of.\n",
    "    \n",
    "    Returns:\n",
    "    int: The factorial of the input number.\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "n = 0\n",
    "result = factorial(n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62f45453-b316-4799-ab3e-556671365a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt -f code\n",
    "Do the same without making the function recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad7df3-5189-4054-a4d1-40a31a5e0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2d405-012a-42f0-ab1a-58c518e53b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
